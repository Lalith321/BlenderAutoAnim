{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3rd Experiment",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h6zVo4_VIqi_X9rB8Ni58cCYAdKfo4Dm",
      "authorship_tag": "ABX9TyNCCJ6R+LXIz5JGZqpjo5gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lalith321/BlenderAutoAnim/blob/master/3rd_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwgo9H6UD9YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MykV_jeNdjTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os,sys,time\n",
        "import sklearn as sk\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "#from sklearn.preprocessing import train_test_split\n",
        "from sklearn.datasets import load_files\n",
        "#from tensorflow_core._api.v2.compat.v1.random.experimental import Generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edVNh36OD0ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHRLhjZS9jbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linking google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PntnVPuBxRkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess1(data):\n",
        "    global X1\n",
        "    data = tf.reshape(data,[300,268,1])\n",
        "    data = tf.image.resize(data,[48,2304])\n",
        "    data = tf.reshape(data,[1,48,48,48]) # Reshaping the data\n",
        "    X1 = np.append(X1,data,axis = 0)\n",
        "    return X1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdWWfsb9er4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive/My Drive\"\n",
        "#TrainData = load_files(\"D:\\\\projects\\\\BlenderAutoAnimator\\\\Train\")\n",
        "TrainData = \"/content/drive/My Drive/Train1\"\n",
        "filenames = []\n",
        "\n",
        "X1 = np.array([],dtype=np.int64).reshape(0,48,48,48)\n",
        "X2 = []\n",
        "\n",
        "for target in os.listdir(TrainData):\n",
        "    print(target)\n",
        "    for f in os.listdir(os.path.join(TrainData+\"/\"+target)):\n",
        "        o_data = (np.loadtxt(TrainData+\"/\"+target+\"/\"+f))\n",
        "        o_data = o_data.reshape(int(o_data.shape[0]/67),67,4) # Turn the image to (300, 67, 4)\n",
        "        initial = o_data.shape[0]\n",
        "        if(initial<=300):\n",
        "            data = o_data\n",
        "            additionals = int((300-initial)%initial) # If image.shape[1] is less than 300 then add the extra data starting from frame 1 (10's digit)\n",
        "            for i in range(int((300-initial)/initial)):\n",
        "                data = np.vstack((data,o_data)) # additional daata (100's digit)\n",
        "            data = np.vstack((data,o_data[:additionals])) # Create a bunch of data by stacking it one on the other\n",
        "            # Special steps for resizing 3D data\n",
        "            X1 = preprocess1(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlquxmMJbcZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUuGQaiKe0wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess2(preprocessing_input):\n",
        "    global max_,min_\n",
        "    preprocessing_input = np.asarray(preprocessing_input)\n",
        "    preprocessing_input = preprocessing_input.reshape(preprocessing_input.shape[0], 48, 48, 48, 1).astype('float32')\n",
        "    max_ = tf.math.reduce_max(preprocessing_input)\n",
        "    min_ = tf.math.reduce_min(preprocessing_input)\n",
        "    preprocessing_input = (preprocessing_input - min_) / (max_-min_) # Normalize the images to [-1, 1]\n",
        "    return preprocessing_input\n",
        "\"\"\"for element in train_dataset:\n",
        "    print(element.shape[0])\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2CTHDMzzS85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = preprocess2(X1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fee-RDYbgGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htR4inNptnVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape_1 = 57\n",
        "dynamic_scale_1 = o_data[1]/shape_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l9lTuTtWrCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 6\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8auBjE9Jdu6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcpqVsNj81L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator Code\n",
        "def generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(12*12*12*100, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Reshape((12,12,12,100)))\n",
        "    assert model.output_shape == (None, 12,12,12,100)\n",
        "\n",
        "    #Required (10,16,2) same:padding\n",
        "    model.add(layers.Conv3DTranspose(512, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", use_bias=False))\n",
        "    assert model.output_shape == (None, 12,12,12,512)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    #Required (20,32,4) same:padding\n",
        "    model.add(layers.Conv3DTranspose(256, (2, 2, 2), strides=(1, 1, 1), padding=\"same\", use_bias=False))\n",
        "    assert model.output_shape == (None, 12,12,12,256)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    \n",
        "    #Required (40,32,4) same:padding\n",
        "    model.add(layers.Conv3DTranspose(128, (2, 2, 2), strides=(1, 1, 1), padding=\"same\", use_bias=False))\n",
        "    assert model.output_shape == (None, 12,12,12,128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    #Required (20,32,4) same:padding\n",
        "    model.add(layers.Conv3DTranspose(64, (6, 6, 6), strides=(4, 4, 4), padding=\"same\", use_bias=False))\n",
        "    assert model.output_shape == (None, 48,48,48,64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    #Required (99,32,4) valid:padding    (3,2,1)\n",
        "    model.add(layers.Conv3DTranspose(1, (2, 2, 2), strides=(1, 1, 1), padding=\"same\", use_bias=False, activation=\"tanh\"))\n",
        "    assert model.output_shape == (None, 48,48,48,1) #final must be (48,48,48,1)\n",
        "    return model\n",
        "\n",
        "generator = generator_model()\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGGWa8KYrLB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class separator(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(separator,self).__init__()\n",
        "\n",
        "    def call(self, inputs, ratio):\n",
        "        #l = inputs[:,:,:int(inputs.shape[2]/ratio)+1,:]\n",
        "        #m = inputs[:,:,inputs.shape[2]-int(inputs.shape[2]/ratio)-1:,:]\n",
        "        l,_ = tf.split(inputs,[int(inputs.shape[2]/ratio)+1,inputs.shape[2]-int(inputs.shape[2]/ratio)-1],2)\n",
        "        _,m = tf.split(inputs,[int(inputs.shape[2]/ratio)-1,inputs.shape[2]-int(inputs.shape[2]/ratio)+1],2)\n",
        "        return l,m\n",
        "\n",
        "x_separator = separator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvp4Gv4789Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator Code\n",
        "def discriminator_model():\n",
        "    visible = layers.Input(shape=(48,48,48,1))\n",
        "\n",
        "    split01, split02 = x_separator(visible, 67/57)\n",
        "    conv11 = layers.Conv3D(32, kernel_size=5)(split01)\n",
        "    conv11 = layers.LeakyReLU()(conv11)\n",
        "    conv21 = layers.Conv3D(32, kernel_size=3)(split02)\n",
        "    conv21 = layers.LeakyReLU()(conv21)\n",
        "    conv22 = layers.Conv3D(32, kernel_size=3)(conv21)\n",
        "    conv22 = layers.LeakyReLU()(conv22)\n",
        "\n",
        "    merge1 = layers.concatenate([conv11,conv22],axis=2)\n",
        "\n",
        "    split11, split12 = x_separator(merge1, 67/57)\n",
        "    #split11, split12 = tf.split(merge1,[int(merge1.shape[2]/ratio),merge1.shape[2]-int(merge1.shape[2]/ratio)],2)\n",
        "    conv12 = layers.Conv3D(32, kernel_size=5)(split11)\n",
        "    conv12 = layers.LeakyReLU()(conv12)\n",
        "    conv23 = layers.Conv3D(32, kernel_size=3)(split12)\n",
        "    conv23 = layers.LeakyReLU()(conv23)\n",
        "    conv24 = layers.Conv3D(32, kernel_size=3)(conv23)\n",
        "    conv24 = layers.LeakyReLU()(conv24)\n",
        "\n",
        "    merge2 = layers.concatenate([conv12,conv24],axis=2)\n",
        "\n",
        "    split21, split22 = x_separator(merge2, 67/57)    \n",
        "    #split21, split22 = tf.split(merge2,[int(merge2.shape[2]/ratio),merge2.shape[2]-int(merge2.shape[2]/ratio)],2)\n",
        "    conv13 = layers.Conv3D(32, kernel_size=5)(split21)\n",
        "    conv13 = layers.LeakyReLU()(conv13)\n",
        "    conv25 = layers.Conv3D(32, kernel_size=3)(split22)\n",
        "    conv25 = layers.LeakyReLU()(conv25)\n",
        "    conv26 = layers.Conv3D(32, kernel_size=3)(conv25)\n",
        "    conv26 = layers.LeakyReLU()(conv26)\n",
        "    \n",
        "    merge3 = layers.concatenate([conv13,conv26],axis=2)\n",
        "    hidden1 = layers.Dense(10, activation='relu')(merge3)\n",
        "    output = layers.Dense(1,activation='relu')(hidden1)\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[visible], outputs=output)\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u2dfcTcAyrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = discriminator_model()\n",
        "decision = discriminator(generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UmKnuAN9DF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3W3_e4C9JZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4,beta_1=0.5)#,beta_2=0.999,epsilon=1e-07)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4,beta_1=0.5)#,beta_2=0.999,epsilon=1e-07)\n",
        "\n",
        "checkpoint_dir = '/content/drive/My Drive/Train_Checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, generator=generator, discriminator=discriminator)\n",
        "manager = tf.train.CheckpointManager(checkpoint, '/content/drive/My Drive/Train_Checkpoints', max_to_keep=3)\n",
        "\n",
        "EPOCHS = 100\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 1\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vNPf3QT9SfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug17IbM09X5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        # Produce images for the GIF as we go\n",
        "        display.clear_output(wait=True)\n",
        "        generate(generator, epoch + 1, seed)\n",
        "\n",
        "        # Save the model every 40 epochs\n",
        "        if (epoch + 1) % 40 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "        \n",
        "        #checkpoint.restore(manager.latest_checkpoint)\n",
        "\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "    # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate(generator, epochs, seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLZu8RB-swd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def original_shape(predictions):\n",
        "    predictions = (predictions[0, :, :, :, 0] * (max_-min_)) + min_\n",
        "    # Getting back in original form\n",
        "    predictions = tf.reshape(predictions,[48,2304,1])\n",
        "    predictions = tf.image.resize(predictions, [300,268])\n",
        "    predictions = tf.reshape(predictions,[300,67,4])\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwYBgsYRspJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(model, epoch, test_input):\n",
        "    # Notice `training` is set to False.\n",
        "    # This is so all layers run in inference mode (batchnorm).\n",
        "    predictions = model(test_input, training=False)\n",
        "    predictions = original_shape(predictions)\n",
        "    print(predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWlL6gz76LL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkdJ_HrrFB9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Save_animation(predictions)\n",
        "    with open(\"/content/drive/My Drive/Result/test23.txt\", 'w') as outfile:\n",
        "        outfile.write('#Array shape: {0}\\n'.format(predictions.shape))\n",
        "        for data_slice in predictions:\n",
        "            np.savetxt(outfile,data_slice)\n",
        "            outfile.write('#New slice\\n')\n",
        "\n",
        "save_animation(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}